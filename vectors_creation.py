# -*- coding: utf-8 -*-
"""Vectors-Creation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K6fwDcgJku6fvHMzeHZc-c3PodrddFVR
"""

import pandas as pd
import seaborn as sns
from gensim.models import FastText
from gensim.models import KeyedVectors
import sent2vec

filename = "/path/to/BioWordVec_PubMed_MIMICIII_d200.bin"
filename2 = "/path/to/BioSentVec_PubMed_MIMICIII-bigram_d700.bin"
data_path = "DataPreprocessing/data"
corpus_data = "corpus_data"

class Dictlist(dict):
    def __setitem__(self, key, value):
        try:
            self[key]
        except KeyError:
            super(Dictlist, self).__setitem__(key, [])
        self[key].append(value)

# Load the model
model = sent2vec.Sent2vecModel()
model.load_model(filename2)

df = pd.read_csv("corpus_data/sra_corpus.txt", sep='\t', names=['id','text'])

data = Dictlist()
for i ,j in df[["id", "text"]].values:
    data[i] = model.embed_sentences([j])

import numpy as np
np.save('corpus_embeddings/sra_embeddings_data.npy', data)

read_dictionary = np.load('corpus_embeddings/sra_embeddings_data.npy',allow_pickle='TRUE').item()





from sentence_transformers import SentenceTransformer
from sentence_transformers.util import cos_sim

model = SentenceTransformer('paraphrase-MiniLM-L6-v2')


#Our sentences we like to encode
sentences = ['This framework generates embeddings for each input sentence',
    'where']

embeddings_data = {}

#Sentences are encoded by calling model.encode()
embeddings = model.encode(sentences)

#Print the embeddings
for sentence, embedding in zip(sentences, embeddings):
    embeddings_data[sentence] = embedding

a = embeddings_data['where']
b =  embeddings_data['This framework generates embeddings for each input sentence']

cos_sim(a, b)

