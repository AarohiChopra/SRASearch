# -*- coding: utf-8 -*-
"""SampleVectorCreation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11a-ojgXL8l0St7OGRMZzycVegHwtMWqc
"""

import pandas as pd
import seaborn as sns
from gensim.models import FastText
from tqdm import tqdm
from gensim.models import KeyedVectors
import sent2vec
from pandarallel import pandarallel
pandarallel.initialize(progress_bar=True)

filename = "/home/akapoor/BioWordVec_PubMed_MIMICIII_d200.bin"
filename2 = "/home/akapoor/BioSentVec_PubMed_MIMICIII-bigram_d700.bin"
data_path = "DataPreprocessing/data"
corpus_data = "corpus_data/"

print("Loading the model...")
# using sentence to vector model.
with tqdm() as bar:
# Load the model
    model = sent2vec.Sent2vecModel()
    model.load_model(filename2)
print("Model loading complete!")

# Commented out IPython magic to ensure Python compatibility.
# %time
txts = ["experiment_corpus.txt"]

print("Loading CSVs")
dfs = {}
with tqdm() as bar:
    # Load the dataset
    for i in txts:
        print("Loading: ", i)
        df = pd.read_csv(f"corpus_data/{i}", sep='\t', names=['id', 'text'])
        df['text'] = df['text'].astype(str)
        df['id'] = df['id'].astype(str)
        dfs[i] = df

print("Loading csvs completed!")

df = dfs['experiment_corpus.txt']

df = df[df.text != 'nan']

df.count()

print("Getting embeddings")
# Generating embeddings just for the text
# Get embeddings
def get_embeddings(row):
    return model.embed_sentences(row['text'])

#df = dfs['sample_corpus.txt']

#df = df[df.text != 'nan']

import numpy as np
list_df = np.array_split(df, 10)

len(list_df[2])

split = 1
for i in list_df:
    i.to_csv(f"corpus_data/experiment_splits/experiment_split{split}.txt", index=False, header=False, sep='\t')
    split+=1

df.head()

df.head()

